<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.6" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.6">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.6" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.0.6',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="tensor数据结构tensor是一种数据结构，是n维空间的数据表达，这里的n被称为tensor的阶，如0阶是一个数，1阶是一个向量，二维就是一个矩阵，三维就是一个立方体 维度要看最左边几个括号，有n个，这个张量就是n维张量 numpynumpy中的数组被称为ndarry    属性 含义     ndarray.ndim 数组的维数   ndarray.shape 数组的维度   ndarray">
<meta name="keywords" content="编程语言,tensor">
<meta property="og:type" content="article">
<meta property="og:title" content="tensor 笔记">
<meta property="og:url" content="http://yoursite.com/2018/05/31/tensor-笔记/index.html">
<meta property="og:site_name" content="welljun&#39;s blog">
<meta property="og:description" content="tensor数据结构tensor是一种数据结构，是n维空间的数据表达，这里的n被称为tensor的阶，如0阶是一个数，1阶是一个向量，二维就是一个矩阵，三维就是一个立方体 维度要看最左边几个括号，有n个，这个张量就是n维张量 numpynumpy中的数组被称为ndarry    属性 含义     ndarray.ndim 数组的维数   ndarray.shape 数组的维度   ndarray">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-06-25T09:25:15.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tensor 笔记">
<meta name="twitter:description" content="tensor数据结构tensor是一种数据结构，是n维空间的数据表达，这里的n被称为tensor的阶，如0阶是一个数，1阶是一个向量，二维就是一个矩阵，三维就是一个立方体 维度要看最左边几个括号，有n个，这个张量就是n维张量 numpynumpy中的数组被称为ndarry    属性 含义     ndarray.ndim 数组的维数   ndarray.shape 数组的维度   ndarray">






  <link rel="canonical" href="http://yoursite.com/2018/05/31/tensor-笔记/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>tensor 笔记 | welljun's blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> 

<div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">welljun's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
          
  <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
</li>

      

      
    </ul>
  

  
    

    
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  


  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/31/tensor-笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="welljun">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welljun's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">tensor 笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-31T23:13:24+08:00">2018-05-31</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="tensor数据结构"><a href="#tensor数据结构" class="headerlink" title="tensor数据结构"></a>tensor数据结构</h3><p>tensor是一种数据结构，是n维空间的数据表达，这里的n被称为tensor的阶，如0阶是一个数，1阶是一个向量，二维就是一个矩阵，三维就是一个立方体</p>
<p>维度要看最左边几个括号，有n个，这个张量就是n维张量</p>
<h4 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h4><p>numpy中的数组被称为<code>ndarry</code></p>
<table>
<thead>
<tr>
<th>属性</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ndarray.ndim</code></td>
<td>数组的维数</td>
</tr>
<tr>
<td><code>ndarray.shape</code></td>
<td>数组的维度</td>
</tr>
<tr>
<td><code>ndarray.size</code></td>
<td>数组中所有元素的大小</td>
</tr>
<tr>
<td><code>ndarray.dtype</code></td>
<td>数组中元素的类型</td>
</tr>
<tr>
<td><code>ndarray.itemsize</code></td>
<td>数组中每个元素的大小，单位为字节</td>
</tr>
<tr>
<td><code>ndarray.data</code></td>
<td>存储数组元素的缓冲</td>
</tr>
</tbody>
</table>
<h3 id="简易tensor语言设计与实现"><a href="#简易tensor语言设计与实现" class="headerlink" title="简易tensor语言设计与实现"></a>简易tensor语言设计与实现</h3><h4 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1.数据结构"></a>1.数据结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tensor</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ndim, shape, data, dtype)</span>:</span></span><br><span class="line">        self.ndim = ndim <span class="comment">#维数</span></span><br><span class="line">        self.shape = shape <span class="comment">#形状</span></span><br><span class="line">        self.data = data <span class="comment">#数据</span></span><br><span class="line">        self.dtype = dtype <span class="comment">#类型</span></span><br></pre></td></tr></table></figure>
<p>包含了基本的属性，<code>ndim</code>代表维度数，<code>shape</code>代表tensor的形状，<code>data</code>代表其中的数据，<code>dtype</code>代表存储的数据类型。</p>
<h4 id="2-数据初始化"><a href="#2-数据初始化" class="headerlink" title="2. 数据初始化"></a>2. 数据初始化</h4><p>数据生成的方法包括<code>rand</code>、<code>one</code>、<code>zero</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_tensor</span><span class="params">(shape, index, data)</span>:</span></span><br><span class="line">    <span class="comment">#抽象生成函数</span></span><br><span class="line">    <span class="keyword">if</span> index &gt;= len(shape):</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, shape[index]):</span><br><span class="line">            temp.append(init_tensor(shape, index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="keyword">return</span> temp</span><br></pre></td></tr></table></figure>
<p>生成<code>tensor</code>需要的参数包括<code>shape</code>、<code>data</code>，index递归构造过程中传递的参数。</p>
<p><strong>原理</strong>：由于是多层结构，因此选择使用递归，目的是为了从底层从下而上构造，每一层通过新构造的<code>[]</code>拼接下一层构造完成的结构，最终就能生成按照<code>shape</code>生成的<code>tensor</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_random</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Tensor(len(shape), shape, random(shape, <span class="number">0</span>), <span class="string">"Tensor"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_one</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Tensor(len(shape), shape, init_tensor(shape, <span class="number">0</span>, <span class="number">1</span>), <span class="string">"Tensor"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_zero</span><span class="params">(shape)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Tensor(len(shape), shape, init_tensor(shape, <span class="number">0</span>, <span class="number">0</span>), <span class="string">"Tensor"</span>)</span><br></pre></td></tr></table></figure>
<p>通过构造函数包装不同的方法生成对应的tensor</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">shape = [<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">b = init_random(shape)</span><br><span class="line">c = init_one(shape)</span><br><span class="line">d = init_zero(shape)</span><br><span class="line">print(<span class="string">"[rand]\nb_ndim:&#123;0&#125;, b_shape:&#123;1&#125;, b_dtype:&#123;2&#125;\nb_data:&#123;3&#125;"</span>.format(b.ndim, b.shape, b.dtype, b.data))</span><br><span class="line">print(<span class="string">"[one]\nc_ndim:&#123;0&#125;, c_shape:&#123;1&#125;, c_dtype:&#123;2&#125;\nc_data:&#123;3&#125;"</span>.format(c.ndim, c.shape, c.dtype, c.data))</span><br><span class="line">print(<span class="string">"[zero]\nd_ndim:&#123;0&#125;, d_shape:&#123;1&#125;, d_dtype:&#123;2&#125;\nd_data:&#123;3&#125;"</span>.format(d.ndim, d.shape, d.dtype, d.data))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[rand]</span><br><span class="line">b_ndim:<span class="number">2</span>, b_shape:[<span class="number">3</span>, <span class="number">3</span>], b_dtype:Tensor</span><br><span class="line">b_data:[[<span class="number">5</span>, <span class="number">9</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br><span class="line">[one]</span><br><span class="line">c_ndim:<span class="number">2</span>, c_shape:[<span class="number">3</span>, <span class="number">3</span>], c_dtype:Tensor</span><br><span class="line">c_data:[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">[zero]</span><br><span class="line">d_ndim:<span class="number">2</span>, d_shape:[<span class="number">3</span>, <span class="number">3</span>], d_dtype:Tensor</span><br></pre></td></tr></table></figure>
<h4 id="3-生成指定结构的tensor"><a href="#3-生成指定结构的tensor" class="headerlink" title="3. 生成指定结构的tensor"></a>3. 生成指定结构的tensor</h4><p>由于python支持多层列表的识别，和生成，但是无法得到<code>shape</code>信息，因此需要生成<code>tensor</code>信息还需要分析<code>shape</code>信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyze_tensor</span><span class="params">(tensor, shape)</span>:</span></span><br><span class="line">    <span class="comment">#分析结构返回shape</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(tensor, list):</span><br><span class="line">        shape.append(len(tensor))</span><br><span class="line">        analyze_tensor(tensor[<span class="number">0</span>], shape) </span><br><span class="line">    <span class="keyword">return</span> shape</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：这里同样使用递归来分析，使用<code>isinstance()</code>函数来判断当前遍历层的元素是否为list来判定是否遍历到最底层，在遍历每一层的时候使用<code>len()</code>得到当前层的个数信息，最后返回<code>shape</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_by_list</span><span class="params">(data)</span>:</span></span><br><span class="line">    shape = analyze_tensor(data, [])</span><br><span class="line">    <span class="keyword">return</span> Tensor(len(shape), shape, data, <span class="string">"tensor"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">z = [[<span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">7</span>]]</span><br><span class="line">a = init_by_list(z)</span><br><span class="line">print(<span class="string">"[data]\na_ndim:&#123;0&#125;, a_shape:&#123;1&#125;, a_dtype:&#123;2&#125;\na_data:&#123;3&#125;"</span>.format(a.ndim, a.shape, a.dtype, a.data))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[data]</span><br><span class="line">a_ndim:<span class="number">2</span>, a_shape:[<span class="number">3</span>, <span class="number">3</span>], a_dtype:tensor</span><br><span class="line">a_data:[[<span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">7</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h3><p>现在假设通过解析字符串来生成对应的<code>tensor</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyse_statement</span><span class="params">(str)</span>:</span></span><br><span class="line">    <span class="comment"># 解析输入生成语句</span></span><br><span class="line">    str_split = str.split(<span class="string">'='</span>) <span class="comment"># 将输入语句按照等号划分两半</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 去除分割后数组前后多余空格</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(str_split)):</span><br><span class="line">        str_split[i] = str_split[i].strip()</span><br><span class="line">    <span class="comment"># 如果是生成自定义结构，等号后面第一个字符为'['</span></span><br><span class="line">    <span class="keyword">if</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'['</span>:</span><br><span class="line">        print(<span class="string">'[生成自定义结构] 变量名：&#123;0&#125;, 参数：&#123;1&#125;'</span>.format(str_split[<span class="number">0</span>], str_split[<span class="number">1</span>]))</span><br><span class="line">        shape = analyze_structure(str_split[<span class="number">1</span>])</span><br><span class="line">        data = <span class="string">""</span>.join(re.split(<span class="string">r"\[|\]| "</span>, str_split[<span class="number">1</span>])) <span class="comment"># 去除'[] '</span></span><br><span class="line">        print(<span class="string">'参数：&#123;0&#125;'</span>.format(data))</span><br><span class="line">        data = data.split(<span class="string">','</span>)</span><br><span class="line">        globals()[str_split[<span class="number">0</span>]] = init_by_data(shape, data) <span class="comment"># 全局</span></span><br><span class="line">    <span class="comment"># 如果是其他生成</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'r'</span>:   </span><br><span class="line">            para = str_split[<span class="number">1</span>][<span class="number">5</span>:<span class="number">-1</span>]</span><br><span class="line">            print(<span class="string">'[rand] 变量名：&#123;0&#125;, 形状：&#123;1&#125;'</span>.format(str_split[<span class="number">0</span>], para))</span><br><span class="line">        <span class="keyword">elif</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'o'</span>:</span><br><span class="line">            para = str_split[<span class="number">1</span>][<span class="number">4</span>:<span class="number">-1</span>]</span><br><span class="line">            print(<span class="string">'[one] 变量名：&#123;0&#125;, 形状：&#123;1&#125;'</span>.format(str_split[<span class="number">0</span>], para))</span><br><span class="line">        <span class="keyword">elif</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'z'</span>:</span><br><span class="line">            para = str_split[<span class="number">1</span>][<span class="number">5</span>:<span class="number">-1</span>]</span><br><span class="line">            print(<span class="string">'[zero] 变量名：&#123;0&#125;, 形状：&#123;1&#125;'</span>.format(str_split[<span class="number">0</span>], para))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'输入错误'</span>)</span><br><span class="line">        shape = para.strip(<span class="string">"()"</span>).split(<span class="string">','</span>) <span class="comment"># 取出参数并存为list</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(shape)): <span class="comment"># 去除多余空格并转换为int</span></span><br><span class="line">             shape[i] = int(shape[i].strip()) </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'r'</span>: </span><br><span class="line">            globals()[str_split[<span class="number">0</span>]] = init_random(shape)</span><br><span class="line">        <span class="keyword">elif</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'o'</span>:</span><br><span class="line">            globals()[str_split[<span class="number">0</span>]] = init_one(shape)</span><br><span class="line">        <span class="keyword">elif</span> str_split[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">'z'</span>:</span><br><span class="line">            globals()[str_split[<span class="number">0</span>]] = init_zero(shape)</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：首先通过等号将语句分成两部分，第一部分为变量名，第二部分为数据部分，将多余的空格去掉后，分析右边的语句，判断是否为按照指定结构生成还是按照函数来生成，分两种情况：</p>
<ol>
<li><p><strong>按照指定结构生成</strong></p>
<p>需要解析string字符串，通过<code>analyze_structure()</code>方法得到对应的<code>shape</code>信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyze_structure</span><span class="params">(str)</span>:</span></span><br><span class="line">    <span class="comment"># 分析指定结构字符串shape</span></span><br><span class="line">    str = <span class="string">""</span>.join(str.split(<span class="string">" "</span>))</span><br><span class="line">    shape = []</span><br><span class="line">    count = <span class="number">1</span> <span class="comment"># 最后一维个数</span></span><br><span class="line">    <span class="comment"># 计算维度数和最后一维个数</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> str:</span><br><span class="line">        <span class="keyword">if</span> c == <span class="string">'['</span>:</span><br><span class="line">            shape.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> c == <span class="string">','</span>:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> c == <span class="string">']'</span>:</span><br><span class="line">            shape[len(shape) - <span class="number">1</span>] = count</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    stack = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> str:</span><br><span class="line">        <span class="keyword">if</span> c == <span class="string">'['</span>:</span><br><span class="line">            stack.append(c)</span><br><span class="line">        <span class="keyword">elif</span> c == <span class="string">']'</span>:</span><br><span class="line">            stack.pop()</span><br><span class="line">            <span class="keyword">if</span> len(stack) &gt; <span class="number">0</span>:</span><br><span class="line">                shape[len(stack)<span class="number">-1</span>] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 修正shape</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(shape)<span class="number">-1</span>):</span><br><span class="line">        shape[len(shape)<span class="number">-1</span> - i] = shape[len(shape) - <span class="number">1</span> - i] / shape[len(shape) - <span class="number">2</span> - i]</span><br><span class="line">    print(<span class="string">"分析当前字符串形状:&#123;0&#125;"</span>.format(shape))</span><br><span class="line">    <span class="keyword">return</span> shape</span><br></pre></td></tr></table></figure>
<p><strong>原理：</strong>主要思路通过括号匹配，可以先通过<code>左中括号</code>得到维度数信息，然后统计第一个遇到的最底层list可以得到最后一个维度的大小，然后重新左到右匹配，遇到<code>左中括号</code>就弹入<code>栈</code>，遇到<code>右中括号</code>就将<code>栈</code>中最顶的<code>左中括号</code>弹出，弹出后当前<code>栈</code>内的<code>左中括号</code>个数代表当前括号组所在的层级，由于这样匹配会统计所有的同级组，因此在统计完之后需要修正，只需要从前到后除以后一个数就可以得到正确的<code>shape</code>信息。</p>
<p>在得到shape信息后还需要得到生成的具体信息，只需要将所有的括号、空格去掉按照逗号分割，就可以得到<code>data</code>的一维数组信息。然后通过<code>create_tensor_by_structure()</code>生成对应的<code>tensor</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tensor_by_structure</span><span class="params">(shape, data, index)</span>:</span></span><br><span class="line">    <span class="comment"># 根据data和shape生成特定格式tensor</span></span><br><span class="line">    <span class="keyword">if</span> index &gt;= len(shape):</span><br><span class="line">        c = int(data[<span class="number">0</span>])</span><br><span class="line">        data.pop(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> c</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        temp = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, shape[index]):</span><br><span class="line">            temp.append(create_tensor_by_structure(shape, data, index+<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> temp</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_by_data</span><span class="params">(shape, data)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Tensor(len(shape), shape, create_tensor_by_structure(shape, data, <span class="number">0</span>), <span class="string">"tensor"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>原理：</strong>与前面生成方法类似，不同的是在返回数据的时候通过一维数组中取得，再包装成<code>init_by_data</code>方法生成<code>tensor</code>数据。</p>
</li>
<li><p><strong>利用函数构建</strong></p>
<p>这里预先构建的函数包括<code>rand()</code>、<code>one()</code>、<code>zero()</code>，通过判断首字母的方法判定是使用哪个方法，然后通过<code>split</code>得到<code>shape</code>的list信息，再调用对应的方法构建</p>
</li>
</ol>
<p>在最后的生成语句中，由于要使用变量来创建变量，因此用到<code>globals()</code>函数直接在全局变量表中添加对应的信息。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">"test1 = [[[1, 2], [4, 5], [7, 8]]]"</span></span><br><span class="line">analyse_statement(str1)</span><br><span class="line">print(<span class="string">"test1:&#123;0&#125;"</span>.format(test1.data))</span><br><span class="line">print(<span class="string">"--------------------------------"</span>)</span><br><span class="line">str2 = <span class="string">"test2 = one((2,2))"</span></span><br><span class="line">analyse_statement(str2)</span><br><span class="line">print(<span class="string">"test2:&#123;0&#125;"</span>.format(test2.data))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[生成自定义结构] 变量名：test1, 参数：[[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">8</span>]]]</span><br><span class="line">分析得到当前字符串形状:[<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">参数：<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">8</span></span><br><span class="line">test1:[[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">8</span>]]]</span><br><span class="line">--------------------------------</span><br><span class="line">[one] 变量名：test2, 形状：(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">test2:[[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="算术操作"><a href="#算术操作" class="headerlink" title="算术操作"></a>算术操作</h3><h4 id="1-加法、点乘"><a href="#1-加法、点乘" class="headerlink" title="1. 加法、点乘"></a>1. 加法、点乘</h4><p><strong>Tensor运算合法性</strong>：从<code>shape</code>最后一维开始比较，如果相同，则比较前一位，如果不相同，有1则1的一方通过广播拓展成相同值，而维度数少的一方也可以通过广播数增加维度数达成一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">operate_tensor</span><span class="params">(tensor1, tensor2, operator)</span>:</span></span><br><span class="line">    <span class="comment"># 运算包装</span></span><br><span class="line">    <span class="comment"># 判断维度时候为0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tensor1, list):</span><br><span class="line">        temp = tensor1</span><br><span class="line">        tensor1 = []</span><br><span class="line">        tensor1.append(temp)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tensor2, list):</span><br><span class="line">        temp = tensor2</span><br><span class="line">        tensor2 = []</span><br><span class="line">        tensor2.append(temp)</span><br><span class="line">    shape_x = analyze_tensor(tensor1, [])</span><br><span class="line">    shape_y = analyze_tensor(tensor2, [])</span><br><span class="line">    <span class="keyword">if</span> len(shape_x) &lt; len(shape_y): <span class="comment"># 交换</span></span><br><span class="line">        shape_x, shape_y = shape_y, shape_x</span><br><span class="line">        tensor1, tensor2 = tensor2, tensor1</span><br><span class="line">    print(<span class="string">'tensor1: &#123;1&#125; shape: &#123;0&#125;'</span>.format(shape_x, tensor1))</span><br><span class="line">    print(<span class="string">'tensor2: &#123;1&#125; shape: &#123;0&#125;'</span>.format(shape_y, tensor2))</span><br><span class="line">    <span class="comment"># 如果维度相同</span></span><br><span class="line">    <span class="keyword">if</span> shape_x == shape_y: </span><br><span class="line">        print(<span class="string">"【执行运算...】\ntensor1:&#123;1&#125;\ntensor2:&#123;0&#125;\noperator:&#123;2&#125;"</span>.format(tensor2,tensor1,operator))</span><br><span class="line">        data = cal_tensor(tensor1, tensor2, [], operator)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 从尾部开始比较</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(shape_y)):</span><br><span class="line">            <span class="keyword">if</span> shape_x[len(shape_x) - i - <span class="number">1</span>] != shape_y[len(shape_y) - i - <span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">if</span> shape_x[len(shape_x) - i - <span class="number">1</span>] == <span class="number">1</span>:</span><br><span class="line">                    <span class="comment"># print("【存在1拓展...】")</span></span><br><span class="line">                    shape_x[len(shape_x) - i - <span class="number">1</span>] = shape_y[len(shape_y) - i - <span class="number">1</span>]</span><br><span class="line">                    shape_temp = shape_x[<span class="number">0</span>:len(shape_x) - i]</span><br><span class="line">                    <span class="comment"># print("更新shape_1: &#123;0&#125;".format(shape_x))</span></span><br><span class="line">                    <span class="comment"># 取得当前为1的内容</span></span><br><span class="line">                    tensor_temp = tensor1</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(shape_x) - i):</span><br><span class="line">                        tensor_temp = tensor_temp[<span class="number">0</span>]</span><br><span class="line">                    tensor1 = init_tensor(shape_temp, <span class="number">0</span>, tensor_temp)</span><br><span class="line">                    <span class="comment"># print("更新tensor1: &#123;0&#125;".format(tensor1))</span></span><br><span class="line">                <span class="keyword">elif</span> shape_y[len(shape_y) - i - <span class="number">1</span>] == <span class="number">1</span>:</span><br><span class="line">                    <span class="comment"># print("【存在1拓展...】")</span></span><br><span class="line">                    shape_y[len(shape_y) - i - <span class="number">1</span>] = shape_x[len(shape_x) - i - <span class="number">1</span>]</span><br><span class="line">                    shape_temp = shape_y[<span class="number">0</span>:len(shape_y) - i]</span><br><span class="line">                    <span class="comment"># print("更新shape_2: &#123;0&#125;".format(shape_y))</span></span><br><span class="line">                     <span class="comment"># 取得当前为1的内容</span></span><br><span class="line">                    tensor_temp = tensor2</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(shape_y) - i):</span><br><span class="line">                        tensor_temp = tensor_temp[<span class="number">0</span>]</span><br><span class="line">                    tensor2 = init_tensor(shape_temp, <span class="number">0</span>, tensor_temp)</span><br><span class="line">                    <span class="comment"># print("更新tensor2: &#123;0&#125;".format(tensor2))</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">"broadcasting failed!"</span>)</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 确定新shape</span></span><br><span class="line">        <span class="keyword">if</span> len(shape_x) != len(shape_y):</span><br><span class="line">            <span class="comment"># print("【拓展维度...】")</span></span><br><span class="line">            <span class="comment"># 拓展tensor2</span></span><br><span class="line">            shape = shape_x[<span class="number">0</span>:(len(shape_x) - len(shape_y))]</span><br><span class="line">            tensor2 = init_tensor(shape, <span class="number">0</span>, tensor2)</span><br><span class="line">            <span class="comment"># print('更新shape_2:&#123;0&#125;\n更新tensor2:&#123;1&#125;'.format(shape_x, tensor2))</span></span><br><span class="line">        print(<span class="string">"【执行运算...】\ntensor1:&#123;1&#125;\ntensor2:&#123;0&#125;\noperator:&#123;2&#125;"</span>.format(tensor2,tensor1,operator))</span><br><span class="line">        data = cal_tensor(tensor1, tensor2, [], operator)</span><br><span class="line">        <span class="comment"># print("data:&#123;0&#125;".format(data))</span></span><br><span class="line">    result = create_tensor_by_structure(analyze_tensor(tensor1, []), data, <span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"【结果】：&#123;0&#125;"</span>.format(result))</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p><strong>原理：</strong>首先判断输入是否具有0维tensor，如果有则广播成1维，如果维度数和维度都相同，则通过<code>cal_tensor()</code>计算结果；如果不同，从尾部开始比较，如果当前比较维度不相同，则判断是否存在1，如果存在1，则广播拓展后再运算。最后通过<code>create_tensor_by_structure()</code>使用<code>shape</code>和一维<code>data</code>构建结果的<code>tensor</code>。</p>
<blockquote>
<p>广播：以1当前维度为分割线，将1后面维度的部分看成一个整体，shape为shape[0:len(shape) - i]，通过<code>init_tensor()</code>构建新的tensor后，则完成拓展；如果是维度数少的情况，则通过将整个tensor看成整体，shape为shape_x[0:(len(shape_x) - len(shape_y))]，再通过<code>init_tensor()</code>构建新tensor。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_tensor</span><span class="params">(tensor1, tensor2, tensor3, operator)</span>:</span></span><br><span class="line">    <span class="comment"># 统一操作加减点乘（相同维度）</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(tensor1, list):</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tensor1)):</span><br><span class="line">            cal_tensor(tensor1[i], tensor2[i], tensor3, operator)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> operator == <span class="string">'+'</span>:</span><br><span class="line">            tensor3.append(tensor1 + tensor2)</span><br><span class="line">        <span class="keyword">elif</span> operator == <span class="string">'-'</span>:</span><br><span class="line">            tensor3.append(tensor1 - tensor2)</span><br><span class="line">        <span class="keyword">elif</span> operator == <span class="string">'.'</span>:</span><br><span class="line">            tensor3.append(tensor1 * tensor2)</span><br><span class="line">    <span class="keyword">return</span> tensor3</span><br></pre></td></tr></table></figure>
<p><strong>原理：</strong>通过递归遍历多层list，遍历到数据的时候执行相对应的操作，最后返回一维数组。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">y = [<span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">z = operate_tensor(x,y,<span class="string">'.'</span>)</span><br><span class="line">print(<span class="string">"result:&#123;0&#125;"</span>.format(z))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor1: [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]] shape: [<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">5</span>, <span class="number">6</span>] shape: [<span class="number">2</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">tensor2:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">5</span>, <span class="number">12</span>], [<span class="number">15</span>, <span class="number">24</span>]]</span><br><span class="line">result:[[<span class="number">5</span>, <span class="number">12</span>], [<span class="number">15</span>, <span class="number">24</span>]]</span><br></pre></td></tr></table></figure>
<h4 id="2-叉乘"><a href="#2-叉乘" class="headerlink" title="2. 叉乘"></a>2. 叉乘</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tra_tensor</span><span class="params">(tensor_x, tensor_y, result)</span>:</span></span><br><span class="line">    <span class="comment"># 叉乘底层</span></span><br><span class="line">    temp = [<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> isinstance(tensor_x, list):   </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tensor_x)):</span><br><span class="line">            <span class="keyword">if</span> isinstance(tensor_x[i], list):</span><br><span class="line">                tra_tensor(tensor_x[i], tensor_y, result)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp_one = operate_tensor(tensor_x[i], tensor_y[i],<span class="string">'.'</span>)</span><br><span class="line">                temp = operate_tensor(temp_one, temp, <span class="string">'+'</span>)</span><br><span class="line">        <span class="keyword">if</span> temp != [<span class="number">0</span>]:</span><br><span class="line">            result.append(temp)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dot</span><span class="params">(tensor_x, tensor_y)</span>:</span></span><br><span class="line">    <span class="comment"># 叉乘外层</span></span><br><span class="line">    print(<span class="string">"tensor_x:&#123;0&#125;\ntensor_y:&#123;1&#125;"</span>.format(tensor_x, tensor_y))</span><br><span class="line">    shape_x = analyze_tensor(tensor_x, [])</span><br><span class="line">    shape_y = analyze_tensor(tensor_y, [])</span><br><span class="line">    <span class="keyword">if</span> shape_x[<span class="number">-1</span>] == shape_y[<span class="number">0</span>]:</span><br><span class="line">        <span class="comment"># x最底层与y顶层相乘</span></span><br><span class="line">        <span class="comment"># 遍历所有x底层</span></span><br><span class="line">        result = tra_tensor(tensor_x, tensor_y, [])</span><br><span class="line">        shape_z = analyze_tensor(result, [])</span><br><span class="line">        print(<span class="string">"shape_x:&#123;0&#125;\nshape_y;&#123;1&#125;\nshape_z:&#123;2&#125;"</span>.format(shape_x, shape_y, shape_z))</span><br><span class="line">        print(<span class="string">"【叉乘结果】:&#123;0&#125;"</span>.format(result))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"输入不合法！"</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>公式：<code>A[m1*n1*k1] * B[m2,n2,k2] = C[m1][n1][n2][k2]</code></p>
<p>且k1 = m2</p>
<p><code>C[i][j][l][r] = sum_{t=1…k1} (A[i][j][t] * B[t][l][r])</code></p>
</blockquote>
<p><strong>原理：</strong>因此需要将x的所有最底层与y的最顶层相乘，这里递归遍历x最底层，使用之前定义的操作对<code>tensor</code>进行运算，返回结果。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">y = [[[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>, <span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>]],[[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>, <span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>]]] </span><br><span class="line">dot(x, y)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">➜  notebooks git:(master) ✗ python <span class="string">"/Users/welljun06/github/myTensor/tensor.py"</span></span><br><span class="line">tensor1: [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]] shape: [<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">5</span>, <span class="number">6</span>] shape: [<span class="number">2</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">tensor2:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">5</span>, <span class="number">12</span>], [<span class="number">15</span>, <span class="number">24</span>]]</span><br><span class="line">result:[[<span class="number">5</span>, <span class="number">12</span>], [<span class="number">15</span>, <span class="number">24</span>]]</span><br><span class="line">tensor_x:[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">tensor_y:[[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]], [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]]</span><br><span class="line">tensor1: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">1</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor2:[[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor1: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">0</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor2:[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>]]</span><br><span class="line">operator:+</span><br><span class="line">【结果】：[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor1: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">2</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor2:[[<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">10</span>, <span class="number">12</span>], [<span class="number">14</span>, <span class="number">16</span>], [<span class="number">18</span>, <span class="number">20</span>]]</span><br><span class="line">tensor1: [[<span class="number">10</span>, <span class="number">12</span>], [<span class="number">14</span>, <span class="number">16</span>], [<span class="number">18</span>, <span class="number">20</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">10</span>, <span class="number">12</span>], [<span class="number">14</span>, <span class="number">16</span>], [<span class="number">18</span>, <span class="number">20</span>]]</span><br><span class="line">tensor2:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">operator:+</span><br><span class="line">【结果】：[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]]</span><br><span class="line">tensor1: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">3</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor2:[[<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">3</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]]</span><br><span class="line">tensor1: [[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">0</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]]</span><br><span class="line">tensor2:[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>]]</span><br><span class="line">operator:+</span><br><span class="line">【结果】：[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]]</span><br><span class="line">tensor1: [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [<span class="number">4</span>] shape: [<span class="number">1</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">tensor2:[[<span class="number">4</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">4</span>]]</span><br><span class="line">operator:.</span><br><span class="line">【结果】：[[<span class="number">20</span>, <span class="number">24</span>], [<span class="number">28</span>, <span class="number">32</span>], [<span class="number">36</span>, <span class="number">40</span>]]</span><br><span class="line">tensor1: [[<span class="number">20</span>, <span class="number">24</span>], [<span class="number">28</span>, <span class="number">32</span>], [<span class="number">36</span>, <span class="number">40</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">tensor2: [[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]] shape: [<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">【执行运算...】</span><br><span class="line">tensor1:[[<span class="number">20</span>, <span class="number">24</span>], [<span class="number">28</span>, <span class="number">32</span>], [<span class="number">36</span>, <span class="number">40</span>]]</span><br><span class="line">tensor2:[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]]</span><br><span class="line">operator:+</span><br><span class="line">【结果】：[[<span class="number">35</span>, <span class="number">42</span>], [<span class="number">49</span>, <span class="number">56</span>], [<span class="number">63</span>, <span class="number">70</span>]]</span><br><span class="line">shape_x:[<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">shape_y;[<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">shape_z:[<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">【叉乘结果】:[[[<span class="number">15</span>, <span class="number">18</span>], [<span class="number">21</span>, <span class="number">24</span>], [<span class="number">27</span>, <span class="number">30</span>]], [[<span class="number">35</span>, <span class="number">42</span>], [<span class="number">49</span>, <span class="number">56</span>], [<span class="number">63</span>, <span class="number">70</span>]]]</span><br></pre></td></tr></table></figure>
<p><strong>分析</strong>：可以看到进行了多次广播操作。</p>
<h3 id="形状操作"><a href="#形状操作" class="headerlink" title="形状操作"></a>形状操作</h3><h4 id="1-shape"><a href="#1-shape" class="headerlink" title="1. shape"></a>1. shape</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shape</span><span class="params">(tensor)</span>:</span></span><br><span class="line">    shape = analyze_tensor(tensor, [])</span><br><span class="line">    print(<span class="string">"shape:&#123;0&#125;"</span>.format(shape))</span><br></pre></td></tr></table></figure>
<p>直接使用上面实现的<code>analyze_tensor()</code>函数实现</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">y=[<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">get_shape(x)</span><br><span class="line">get_shape(y)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：yu</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shape:[<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">shape:[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h4 id="2-reshape"><a href="#2-reshape" class="headerlink" title="2. reshape"></a>2. reshape</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_tensor</span><span class="params">(tensor, new_shape)</span>:</span></span><br><span class="line">    <span class="comment"># 对tensor进行reshape操作</span></span><br><span class="line">    shape = analyze_tensor(tensor, [])</span><br><span class="line">    size = shape_size(shape)</span><br><span class="line">    new_size = shape_size(new_shape)</span><br><span class="line">    <span class="keyword">if</span> size != new_size:</span><br><span class="line">        print(<span class="string">"error"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        data = get_tensor_data(tensor, [])</span><br><span class="line">        new_tensor = create_tensor_by_structure(new_shape, data, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> new_tensor</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：分析原<code>shape</code>的<code>size</code>大小，与<code>new_shape</code>的<code>size</code>进行比较，如果合法则进行reshape操作，将原有数据一维化，利用<code>create_tensor_by_structure()</code>创建新<code>tensor</code>。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">new_shape = [<span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line">x_new = reshape_tensor(x, new_shape)</span><br><span class="line">print(<span class="string">"x_new:&#123;0&#125;"</span>.format(x_new))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_new:[[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>], [<span class="number">4</span>]]</span><br></pre></td></tr></table></figure>
<h4 id="3-size"><a href="#3-size" class="headerlink" title="3. size"></a>3. size</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_tensor_size</span><span class="params">(tensor)</span>:</span></span><br><span class="line">    <span class="comment"># 返回tensor的szie信息</span></span><br><span class="line">    shape = analyze_tensor(tensor, [])</span><br><span class="line">    size = shape_size(shape)</span><br><span class="line">    print(<span class="string">"size:&#123;0&#125;"</span>.format(size))</span><br><span class="line">    <span class="keyword">return</span> size</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：与之前类似，分析<code>tensor</code>的形状，再根据<code>shape</code>信息得到<code>size</code>大小。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">get_tensor_size(x)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">size:<span class="number">4</span></span><br></pre></td></tr></table></figure>
<h4 id="4-slice操作"><a href="#4-slice操作" class="headerlink" title="4. slice操作"></a>4. slice操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_slice</span><span class="params">(inputs, begin, size)</span>:</span></span><br><span class="line">    <span class="comment"># tensor切片操作</span></span><br><span class="line">    inputs = tensor_begin(begin, inputs)</span><br><span class="line">    print(inputs)</span><br><span class="line">    result_data = tensor_size(size, inputs, <span class="number">0</span>, [])</span><br><span class="line">    result = init_by_data(size, result_data)</span><br><span class="line">    print(result.data)</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：slice函数需要三个参数</p>
<ul>
<li>inputs：需要操作的tensor</li>
<li>begin：定位到开始切片的位置</li>
<li>size：切片后的tensor的shape</li>
</ul>
<p>首先处理的是begin参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_begin</span><span class="params">(begin, tensor)</span>:</span></span><br><span class="line">    <span class="comment"># 定位到开始位置</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(begin)):</span><br><span class="line">        <span class="comment"># print(begin[i])</span></span><br><span class="line">        <span class="keyword">if</span> begin[i] != <span class="number">0</span>:</span><br><span class="line">            tensor = tensor[begin[i]:]</span><br><span class="line">            <span class="keyword">if</span> i != <span class="number">0</span>:</span><br><span class="line">                tensor = tensor[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> tensor</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：遍历begin列表，如果当前遍历的begin数据不为0，则从begin[i]行开始取，如果不是第一次操作，则tensor取下一层。最后返回新的tensor，开头即为开始位置。</p>
<p>接下来处理size参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensor_size</span><span class="params">(shape, tensor, index, list)</span>:</span></span><br><span class="line">    <span class="comment"># 按照size遍历tensor</span></span><br><span class="line">    <span class="keyword">if</span> index &gt;= len(shape):</span><br><span class="line">        list.append(tensor)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, shape[index]):</span><br><span class="line">            print(<span class="string">"tensor[i]:&#123;0&#125;,index:&#123;1&#125;"</span>.format(tensor[i], index))</span><br><span class="line">            tensor_size(shape, tensor[i], index + <span class="number">1</span>, list)</span><br><span class="line">    <span class="keyword">return</span> list</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：即按照size的shape来当前tensor进行遍历，将访问到的元素存储为一维list</p>
<p>最后通过<code>init_by_data()</code>创建新的tensor即为slice后产生的tensor</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t = [[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]],[[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]],[[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>]]]</span><br><span class="line">begin = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">size = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">tensor_slice(t, begin, size)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[[3, 3, 3], [4, 4, 4]]]</span><br></pre></td></tr></table></figure>
<h3 id="简易Tensor语言识别"><a href="#简易Tensor语言识别" class="headerlink" title="简易Tensor语言识别"></a>简易Tensor语言识别</h3><p>这里定义两种语句，一种是赋值语句，一种执行语句</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyse_type</span><span class="params">(str)</span>:</span></span><br><span class="line">    <span class="comment"># tensor语言类型检测</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'='</span> <span class="keyword">in</span> str:</span><br><span class="line">        str_split = str.split(<span class="string">'='</span>) <span class="comment"># 将输入语句按照等号划分两半</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(str_split)):</span><br><span class="line">            str_split[i] = str_split[i].strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'*'</span> <span class="keyword">in</span> str:</span><br><span class="line">            <span class="comment"># 叉乘</span></span><br><span class="line">            argv = str_split[<span class="number">1</span>].split(<span class="string">'*'</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(argv)):</span><br><span class="line">                argv[i] = argv[i].strip()</span><br><span class="line">                print(argv[i])</span><br><span class="line">            result = eval(<span class="string">'dot(&#123;0&#125;, &#123;1&#125;)'</span>.format(argv[<span class="number">0</span>], argv[<span class="number">1</span>]))</span><br><span class="line">            shape = get_shape(result)</span><br><span class="line">            exec_str = <span class="string">'&#123;2&#125; = dot(&#123;0&#125;, &#123;1&#125;)'</span>.format(argv[<span class="number">0</span>], argv[<span class="number">1</span>], str_split[<span class="number">0</span>])</span><br><span class="line">            exec(exec_str, globals())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            exec(str, globals())</span><br><span class="line">            shape = eval(<span class="string">'get_shape(&#123;0&#125;)'</span>.format(str_split[<span class="number">1</span>]))</span><br><span class="line">        print(<span class="string">'&#123;0&#125;:tensor&#123;1&#125;'</span>.format(str_split[<span class="number">0</span>], shape))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        exec(str)</span><br></pre></td></tr></table></figure>
<p><strong>原理</strong>：如果有等号，根据等号将语句划分，如果没有‘*’，则是赋值语句，只需要将语句执行后统计shape信息，这里注意<code>exec()</code>要使用<code>globals()</code>参数才能全局创建变量。如果是<code>叉乘</code>情况，则需要将变量取出后通过<code>eval()</code>调用<code>dot()</code>函数，最后一样统计<code>shape</code>信息即可。</p>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str1 = <span class="string">"x = [1, 2]"</span></span><br><span class="line">analyse_type(str1)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x:tensor[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line">str1 = <span class="string">"print(y)"</span></span><br><span class="line">analyse_type(str1)</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br></pre></td></tr></table></figure>
<p><strong>结果测试</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">y = [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>]]</span><br><span class="line">str1 = <span class="string">"z = x * y"</span></span><br><span class="line">analyse_type(str1)</span><br><span class="line">print(<span class="string">"z:&#123;0&#125;"</span>.format(z))</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">z:tensor[<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">z:[[<span class="number">15</span>, <span class="number">18</span>, <span class="number">21</span>]]</span><br></pre></td></tr></table></figure>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/编程语言/" rel="tag"># 编程语言</a>
          
            <a href="/tags/tensor/" rel="tag"># tensor</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/31/Java-反射/" rel="next" title="Java 反射">
                <i class="fa fa-chevron-left"></i> Java 反射
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/12/sjf4j笔记/" rel="prev" title="sjf4j笔记">
                sjf4j笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">welljun</p>
              <p class="site-description motion-element" itemprop="description">不定期更新学习笔记</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">32</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">29</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#tensor数据结构"><span class="nav-number">1.</span> <span class="nav-text">tensor数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#numpy"><span class="nav-number">1.1.</span> <span class="nav-text">numpy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简易tensor语言设计与实现"><span class="nav-number">2.</span> <span class="nav-text">简易tensor语言设计与实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-数据结构"><span class="nav-number">2.1.</span> <span class="nav-text">1.数据结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-数据初始化"><span class="nav-number">2.2.</span> <span class="nav-text">2. 数据初始化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-生成指定结构的tensor"><span class="nav-number">2.3.</span> <span class="nav-text">3. 生成指定结构的tensor</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#语法分析"><span class="nav-number">3.</span> <span class="nav-text">语法分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算术操作"><span class="nav-number">4.</span> <span class="nav-text">算术操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-加法、点乘"><span class="nav-number">4.1.</span> <span class="nav-text">1. 加法、点乘</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-叉乘"><span class="nav-number">4.2.</span> <span class="nav-text">2. 叉乘</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#形状操作"><span class="nav-number">5.</span> <span class="nav-text">形状操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-shape"><span class="nav-number">5.1.</span> <span class="nav-text">1. shape</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-reshape"><span class="nav-number">5.2.</span> <span class="nav-text">2. reshape</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-size"><span class="nav-number">5.3.</span> <span class="nav-text">3. size</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-slice操作"><span class="nav-number">5.4.</span> <span class="nav-text">4. slice操作</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简易Tensor语言识别"><span class="nav-number">6.</span> <span class="nav-text">简易Tensor语言识别</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">welljun</span>

  

  
</div>





<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Mist</a> v6.0.6</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.6"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.6"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.6"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.6"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.6"></script>



  



	





  





  










  





  

  

  

  

  
  

  

  

  

  

</body>
</html>
